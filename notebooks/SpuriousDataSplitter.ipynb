{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51eb83aa-0661-48c8-b75c-0345f9b71c4a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc0c1238-a2bd-48d4-b085-23a518c81adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22361b41-76ac-4d33-ac57-c9b8c24fbf1c",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d67574-17af-4ba3-aafc-e2b95aa55fd1",
   "metadata": {},
   "source": [
    "# Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010b3cee-3c16-47e0-8874-1e6ff05b0f56",
   "metadata": {},
   "source": [
    "This data splitter will explore the spurious correlation that might arise between right and left eye images for a certain severity level. If the model was trained only on right-eye images with non-referrable severity levels (0 and 1) images and tested on right-eye images with referrable severity levels (2 to 4), there are two possible outcomes. If the model learns the spurious relationship between the side of the eye and the severity it will classify the test samples with lower severity scores. If the model is robust enough to the spurious correlation it will most probably classify the test images correctly regardless of the eye-side bias introduced in the data split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88aaee1-2b97-4f74-98ce-0af809a17468",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc33a6b-4215-455e-a6f7-c37cb107ce3c",
   "metadata": {},
   "source": [
    "# Common Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "268d5b1a-cbaf-4b2f-8121-43a92b9edc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_image_extension(image_folder):\n",
    "    IMG_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.bmp')\n",
    "    image_paths = os.listdir(image_folder)\n",
    "    assert len(image_paths), 'The images folder is empty! Please correct the folder path.'\n",
    "    extension = os.path.splitext(image_paths[0])[-1]\n",
    "    assert extension in IMG_EXTENSIONS, 'The images folder must only contain images files with consistent format.'\n",
    "    return extension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95cdc00-0744-4bd4-a93b-33e8befdab99",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d683671f-53ab-4cdf-8a8b-f719dee7cdc0",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0d63274a-a2af-4e1a-b2be-edde2f691735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to image folder\n",
    "IMG_FOLDER = '../datasets/reduced_eyepacs/resized_train_cropped/resized_train_cropped'\n",
    "# Path to the file containing the image labels\n",
    "IMG_LABELS_FILE = '../datasets/reduced_eyepacs/trainLabels_cropped.csv'\n",
    "IMAGE_EXT = detect_image_extension(IMG_FOLDER)\n",
    "SEED = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dbb339-e13b-4be0-a90f-6ce68078c357",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78d3725-b762-4188-8e2b-8405c658fec7",
   "metadata": {},
   "source": [
    "# Splitting data based on eye side, severity and frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37959ccb-522b-4d27-a1de-d512eeb7ac82",
   "metadata": {},
   "source": [
    "## Preparing useful informationm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7b83fb6-77ba-4385-90d4-928faea51182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the labels data\n",
    "df_labels = pd.read_csv(IMG_LABELS_FILE)\n",
    "df_labels = df_labels[['image', 'level']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ada67dfd-cd8c-40ea-89d6-ae1da7e38c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The image info will gather the useful information for splitting\n",
    "df_img_info = df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1707c467-bd5b-42a7-b16c-14faffc16fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separates the patient ID from the eye-side information\n",
    "image_name_info = df_img_info['image'].str.split('_', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3f348b1-1fe3-4998-8305-481ecef904da",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name_info.columns = ['patient_id', 'side']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66150c62-dd52-4a49-89bb-ff4b78d5f1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_info = pd.concat([image_name_info, df_img_info], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ef57d04d-0ac0-43f0-bf80-741ae44f688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_info['image'] = df_img_info['image'].transform(\n",
    "    lambda file_name: os.path.join(IMG_FOLDER, file_name + IMAGE_EXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1dabb059-6677-46c6-b4ca-d3db58b71026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Referrable and non-referrable levels\n",
    "df_img_info['level_group'] = df_img_info['level'].map(lambda val: 'nref' if val <= 1 else 'ref')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0340476b-14e9-4157-9251-fdcb199845d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_info['groups'] = df_img_info['side'] + '_' + df_img_info['level_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1a71925f-9758-4188-9805-2a829b55defa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "right_nref    0.403555\n",
       "left_nref     0.400820\n",
       "left_ref      0.099009\n",
       "right_ref     0.096616\n",
       "Name: groups, dtype: float64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_img_info.groups.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23af7cd1-d972-40c6-9a81-be52ea361105",
   "metadata": {},
   "source": [
    "## Splitting Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3ec527-f85c-4aa2-bbca-fa69f8537c01",
   "metadata": {},
   "source": [
    "First, we need to first define two important sets, the environment set $\\mathcal{E}$ and the labels set $\\mathcal{Y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6b2d43-3986-4865-9646-96257f26405e",
   "metadata": {},
   "source": [
    "$$\n",
    "\\large \\mathcal{E} = \\{left,\\;right\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7f3b7e-25c0-43eb-879d-5a5df963a5c0",
   "metadata": {},
   "source": [
    "$$\n",
    "\\large \\mathcal{Y} = \\{nref,\\; ref\\}\\; \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774f1fd7-c5e4-4d26-9d1f-d370c7d7392a",
   "metadata": {},
   "source": [
    "$where:$\n",
    "\\begin{equation*}    \n",
    "    \\begin{aligned}\n",
    "        &nref = \\{0,1\\}\\\\\n",
    "        &ref = \\{2,3,4\\}\n",
    "    \\end{aligned}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ec0cb2a5-0ec5-4cb2-a56c-47e459dca222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "93c2be5f-282b-40e7-9ced-b2306d02e02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAJORITY_TRAIN_GROUPS = ['left_nref', 'right_ref']\n",
    "MAJORITY_PROPORTION = 0.9\n",
    "VAL_PCT_FROM_TRAIN = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f571985e-0256-4427-9df7-8f2db12f1716",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_major_groups_train = df_img_info.loc[df_img_info.groups.isin(MAJORITY_TRAIN_GROUPS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "62ab0465-d7d8-437e-9f7f-8cb0cc967380",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minor_groups_train = df_img_info.loc[df_img_info.index.difference(df_major_groups_train.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9943f0f6-6eee-4561-84b0-1c10cd765d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_train, minority_test = train_test_split(\n",
    "    df_major_groups_train, \n",
    "    stratify=df_major_groups_train['groups'], \n",
    "    train_size=MAJORITY_PROPORTION,\n",
    "    random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "cf31a0e3-4afe-4abb-acb5-ace888bb9608",
   "metadata": {},
   "outputs": [],
   "source": [
    "minority_train_size = round((len(majority_train) / MAJORITY_PROPORTION) * (1 - MAJORITY_PROPORTION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "3df3ed9a-8e04-46b4-b9c9-aa4032c00fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_test, minority_train = train_test_split(\n",
    "    df_minor_groups_train, \n",
    "    stratify=df_minor_groups_train['groups'], \n",
    "    test_size=minority_train_size / len(df_minor_groups_train),\n",
    "    random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "0ae0f053-0335-4578-be3f-0d5bd7ba14b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking part of training for validation\n",
    "train_images = pd.concat([majority_train, minority_train], axis=0, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "09f71a86-099f-4eab-820e-cce5cceb0e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, val_images = train_test_split(\n",
    "    train_images, \n",
    "    stratify=train_images['groups'],\n",
    "    test_size=VAL_PCT_FROM_TRAIN,\n",
    "    random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c34e894a-7b60-4922-8162-8b3c337d8bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = pd.concat([majority_test, minority_test], axis=0, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "db9285d6-cf25-4d60-a2b4-b39ffb4f085f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "{'left_nref': 0.73, 'left_ref': 0.02, 'right_nref': 0.08, 'right_ref': 0.17}\n",
      "Validation:\n",
      "{'left_nref': 0.73, 'left_ref': 0.02, 'right_nref': 0.08, 'right_ref': 0.18}\n",
      "Test:\n",
      "{'left_nref': 0.08, 'left_ref': 0.18, 'right_nref': 0.72, 'right_ref': 0.02}\n"
     ]
    }
   ],
   "source": [
    "# Group distribution\n",
    "print(f'Train:')\n",
    "pprint(train_images['groups'].value_counts(normalize=True).round(decimals=2).to_dict())\n",
    "print(f'Validation:')\n",
    "pprint(val_images['groups'].value_counts(normalize=True).round(decimals=2).to_dict())\n",
    "print(f'Test:')\n",
    "pprint(test_images['groups'].value_counts(normalize=True).round(decimals=2).to_dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Causal DR (tcc)",
   "language": "python",
   "name": "tcc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
